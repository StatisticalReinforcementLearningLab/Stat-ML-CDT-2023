{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "00ce197e",
   "metadata": {},
   "source": [
    "# Tuesday Afternoon: Inference after Pooling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "009414ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy as sp\n",
    "import numpy_indexed as npi\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "np.random.seed(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f149cf9",
   "metadata": {},
   "source": [
    "# Part 1: Simulating \"Running\" an MRT with Pooling RL"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a000f88a",
   "metadata": {},
   "source": [
    "## Simple Data Generating Environment\n",
    "- \"Covariates\": $O_t = (1, B_t, C_t, D_t)$ where $B_t$ is binary and $C_t$ is continuous and $D_t$ is a measure of \"dosage\"\n",
    "    - Specifically $D_t = \\frac{1}{1-\\gamma} \\sum_{t'=1}^{t-1} \\gamma^{t'} A_{t'}$ for $\\gamma = 0.95$. We normalize by $1-\\gamma$ to ensure $D_t \\in [0,1]$.\n",
    "- Binary action $A_t \\in \\{0, 1\\}$\n",
    "- Rewards are generated as follows:\n",
    "\n",
    "$$\n",
    "R_{t+1} = f_0(O_t)^\\top \\alpha_0 + A_t f_1(O_t)^\\top \\alpha_1 + \\epsilon_t\n",
    "$$\n",
    "\n",
    "where $f_0(O_t) = (1, B_t, C_t, D_t)$, $f_1(O_t) = (1, C_t)$, \n",
    "\n",
    "\n",
    "$\\alpha_0 = (1, -0.8, 0.05, -0.7)$, $\\alpha_1 = (0.3, 0)$, $\\epsilon_t \\sim \\mathcal{N}(0,\\sigma_{\\mathrm{env}}^2)$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "852f91ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "env_params = {\n",
    "    \"alpha0\": np.array([1, 0.5, 0.2, -0.7]),\n",
    "    \"alpha1\": np.array([0.3, 0.05]),\n",
    "    \"sigma_env\": 0.5,\n",
    "    \"B_p\": 0.3,\n",
    "}\n",
    "\n",
    "def generate_reward(state, action, env_params):\n",
    "    base_state = np.array([1, state[1], state[2], state[3]])\n",
    "    treat_state = np.array([1, state[2]])\n",
    "    \n",
    "    base_mean_reward = np.dot( base_state, env_params[\"alpha0\"] )\n",
    "    mean_reward = base_mean_reward + \\\n",
    "                    action * np.dot( treat_state, env_params[\"alpha1\"] )\n",
    "    reward = mean_reward + np.random.normal(scale=env_params[\"sigma_env\"])\n",
    "    return reward\n",
    "        \n",
    "\n",
    "def generate_state(prev_state, prev_action, prev_reward, env_params):\n",
    "    B = np.random.binomial(1, env_params[\"B_p\"])\n",
    "    C = np.random.normal(3, scale=1)\n",
    "    \n",
    "    # Form dosage update\n",
    "    gamma = 0.95\n",
    "    norm_gamma = 1/(1-gamma)\n",
    "    if prev_state is None:\n",
    "        dosage = np.random.binomial(1, 0.5)\n",
    "    else:\n",
    "        dosage = (gamma*norm_gamma*prev_state[-1] + prev_action ) / norm_gamma\n",
    "    \n",
    "    state = np.array([1, B, C, dosage])\n",
    "    return state"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4248d34b",
   "metadata": {},
   "source": [
    "## Pooling Boltzmann Sampler\n",
    "\n",
    "- Boltzmann or Softmax sampling algorithm\n",
    "- RL algorithm's model of the reward:\n",
    "\n",
    "$$\n",
    "\\mathbb{E} [ R_{i,t+1} | H_{i,t-1}, S_{i,t}, A_{i,t} ]= \\phi_0(S_t)^\\top \\beta_0 + A_{i,t} \\phi_1(S_{i,t})^\\top \\beta_1\n",
    "$$\n",
    "\n",
    "where $\\phi_0(S_{i,t}) = (1, C_{i,t})$, $\\phi_1(S_{i,t}) = (1, C_{i,t})$.\n",
    "\n",
    "- Fitting the $\\hat{\\beta}_{t-1}$ using all past user data:\n",
    "$$\n",
    "\\hat{\\beta}_{t-1} = \\big[ \\hat{\\beta}_{t-1,0}, \\hat{\\beta}_{t-1,1} \\big] = \\mathrm{argmin}_{\\beta} \\sum_{i=1}^n \\sum_{t'=1}^{t-1} \\left( R_{i,t'+1} - \\phi_0(S_{t'})^\\top \\beta_0 - A_{i,t'} \\phi_1(S_{i,t'})^\\top \\beta_1 \\right)^2\n",
    "$$\n",
    "\n",
    "- Form action selection probabilities\n",
    "$$\n",
    "\\mathbb{P}(A_{i,t} = 1 | H_{1:n,t}, S_{i,t}) = \\pi_\\min + (1-2\\pi_\\min) * \\left[ 1 + \\exp \\left( - b_{\\mathrm{steep}} \\phi_1(S_{i,t})^\\top \\hat{\\beta}_{t-1,1} \\right) \\right]^{-1}\n",
    "$$\n",
    "Generalized logistic function with $b_{\\mathrm{steep}}$ as hyperparameter.\n",
    "Also, $\\pi_\\min$ constrains action selection probabilities so for $\\pi_{\\min} = 0.1$\n",
    "\n",
    "$$\n",
    "\\mathbb{P}(A_{i,t} = 1 | H_{1:n,t}, S_{i,t}) \\in [\\pi_{\\min}, 1 - \\pi_{\\min}] ~~~~ \\mathrm{with~probability}~1\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6feeeedf",
   "metadata": {},
   "source": [
    "### Pooling Boltzmann Sampler: Algorithm Statistics\n",
    "\n",
    "__Estimating Equation Formulation:__ $\\hat{\\beta}_t$ solves $0 = \\frac{1}{n} \\sum_{i=1}^n \\dot{g}_{i,t}(\\hat{\\beta}_t)$\n",
    "where \n",
    "$$\\dot{g}_{i,t}(\\beta_t) \\triangleq \\sum_{t'=1}^t \\left( R_{i,t'+1} - \\phi_0(S_{t'})^\\top \\beta_0 - A_{i,t'} \\phi_1(S_{i,t'})^\\top \\beta_1 \\right) \\begin{bmatrix} \\phi_0(S_{t'}) \\\\ A_{i,t'} \\phi_1(S_{i,t'}) \\end{bmatrix}$$\n",
    "\n",
    "__Hessian:__\n",
    "$$\\ddot{G}_t \\triangleq - \\sum_{t'=1}^t \\begin{bmatrix} \\phi_0(S_{t'}) \\\\ A_{i,t'} \\phi_1(S_{i,t'}) \\end{bmatrix}^{\\otimes 2}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e3ea6fe9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PoolingBoltzmanSampler:\n",
    "    \n",
    "    def __init__(self, n, pi_min, b_steep=1):\n",
    "        self.pi_min = pi_min\n",
    "        self.b_steep = b_steep\n",
    "        \n",
    "        self.all_policies = [ {\n",
    "            \"policy_num\": 0,\n",
    "            \"R_vec\": None,\n",
    "            \"feat_matrix\": None,\n",
    "            \"beta_est\": None,\n",
    "            \"user_ids\": None,\n",
    "        } ]\n",
    "        self.all_decisions = {}\n",
    "      \n",
    "    \n",
    "    def form_action1_prob(self, beta_est, treat_feats):\n",
    "        lin_est = np.dot(beta_est[-2:], treat_feats)\n",
    "        prob = self.pi_min + (1-2*self.pi_min) / ((1 + np.exp(-self.b_steep * lin_est)))\n",
    "        \n",
    "        return prob\n",
    "    \n",
    "    \n",
    "    def select_action(self, state, user_id):\n",
    "    \n",
    "        # Posterior Mean and Variance for beta_1 (treatment effect)\n",
    "        treat_feats = np.array([state[0], state[2]]).T\n",
    "        beta_est = self.all_policies[-1]['beta_est']\n",
    "        \n",
    "        if beta_est is None:\n",
    "            action1_prob = 0.5\n",
    "            pi_grad = None\n",
    "        else:\n",
    "            action1_prob = self.form_action1_prob(beta_est, treat_feats)\n",
    "            epsilon = np.sqrt(np.finfo(float).eps)\n",
    "            pi_grad = sp.optimize.approx_fprime(beta_est, \n",
    "                                            self.form_action1_prob, \n",
    "                                            epsilon,\n",
    "                                            treat_feats)\n",
    "            \n",
    "        action = np.random.binomial(1, action1_prob)\n",
    "            \n",
    "        policy_num = self.all_policies[-1]['policy_num']\n",
    "        if policy_num in self.all_decisions.keys():\n",
    "            self.all_decisions[policy_num][\"all_user_ids\"].append( user_id )\n",
    "            self.all_decisions[policy_num][\"all_treat_feats\"].append( treat_feats )\n",
    "            self.all_decisions[policy_num][\"all_action1_probs\"].append( action1_prob )\n",
    "            self.all_decisions[policy_num][\"all_actions\"].append( action )\n",
    "            self.all_decisions[policy_num][\"all_pi_grad\"].append( pi_grad )\n",
    "        else:\n",
    "            self.all_decisions[policy_num] = { \n",
    "                \"policy_num\": policy_num,\n",
    "                \"beta_est\": beta_est,\n",
    "                \"all_user_ids\": [user_id],\n",
    "                \"all_treat_feats\": [treat_feats],\n",
    "                \"all_action1_probs\": [action1_prob],\n",
    "                \"all_pi_grad\": [pi_grad],\n",
    "                \"all_actions\": [action],\n",
    "            }\n",
    "    \n",
    "        return action, action1_prob\n",
    "    \n",
    "\n",
    "    def update_algorithm(self, new_states, new_actions, new_rewards, new_user_ids):\n",
    "        alg_info = self.all_policies[-1]\n",
    "        \n",
    "        prev_R_vec = alg_info['R_vec']\n",
    "        prev_feat_matrix = alg_info['feat_matrix']\n",
    "        prev_user_ids = alg_info['user_ids']\n",
    "        \n",
    "        feat_matrix = np.array([new_states[:,0], new_states[:,2], \n",
    "                           new_actions, new_actions*new_states[:,2]]).T\n",
    "        rewards = np.expand_dims(new_rewards, 1)\n",
    "        \n",
    "        if prev_R_vec is None:\n",
    "            new_R_vec = rewards\n",
    "        else:\n",
    "            new_R_vec = np.concatenate([prev_R_vec.copy(), rewards], axis=0)\n",
    "            \n",
    "        if prev_feat_matrix is None:\n",
    "            new_feat_matrix = feat_matrix\n",
    "        else:\n",
    "            new_feat_matrix = np.concatenate([prev_feat_matrix.copy(), feat_matrix], axis = 0)\n",
    "            \n",
    "        if prev_user_ids is None:\n",
    "            all_user_ids = new_user_ids\n",
    "        else:\n",
    "            all_user_ids = np.concatenate([prev_user_ids.copy(), new_user_ids], axis = 0)\n",
    "        \n",
    "        RX = np.sum(new_feat_matrix*new_R_vec, 0)\n",
    "        XX = np.einsum( 'ij,ik->jk', new_feat_matrix, new_feat_matrix )\n",
    "        inv_XX = np.linalg.inv( XX )\n",
    "        beta_est = np.matmul(inv_XX, RX.reshape(-1))\n",
    "        \n",
    "        # ALGORITHM STATISTICS -----------------------------------------\n",
    "        \n",
    "        # Forming estimating equations for beta_est\n",
    "        residuals = new_R_vec.squeeze() - np.matmul(new_feat_matrix, beta_est)\n",
    "        residuals = np.expand_dims(residuals, 1)\n",
    "        raw_est_eqns = residuals * new_feat_matrix\n",
    "        _, est_eqns = npi.group_by(all_user_ids).sum(raw_est_eqns)\n",
    "        \n",
    "        # Forming hessian for beta_est\n",
    "        alg_hessian = - np.einsum('ij,ik->jk', new_feat_matrix, new_feat_matrix) / n\n",
    "            \n",
    "        new_alg_info = {\n",
    "                        \"policy_num\": alg_info['policy_num']+1,\n",
    "                        \"R_vec\": new_R_vec,\n",
    "                        \"feat_matrix\": new_feat_matrix,\n",
    "                        \"beta_est\": beta_est,\n",
    "                        \"est_eqns\": est_eqns,\n",
    "                        \"user_ids\": all_user_ids,\n",
    "                        \"hessian\": alg_hessian,\n",
    "                        }\n",
    "        self.all_policies.append(new_alg_info)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c84994f4",
   "metadata": {},
   "source": [
    "### Preparing the MRT Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6e9f5366",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_empty_study_df(T, n):\n",
    "    dataset_rownames = [\"user_id\", \"decision_t\", \"reward\", \n",
    "                        \"action\", \"action1_prob\", \"intercept\", \"binary\", \"continuous\", \"dosage\"]\n",
    "\n",
    "    # Fill in user_ids and decision times\n",
    "    user_id_all = np.repeat([i for i in range(1,n+1)], T)\n",
    "    decision_t_all = np.tile([i for i in range(1,T+1)], n)\n",
    "    empty_cols = np.empty((n*T, len(dataset_rownames)-2))\n",
    "    empty_cols[:] = np.nan\n",
    "\n",
    "    # Make dataframe to record study data\n",
    "    dataset_entries = np.hstack( [ np.stack([user_id_all, decision_t_all]).T, empty_cols ] )\n",
    "    study_df = pd.DataFrame(dataset_entries, columns=dataset_rownames)\n",
    "\n",
    "    # Change type of columns\n",
    "    type_dict = {\n",
    "        'user_id': int,\n",
    "        'decision_t': int,\n",
    "    }\n",
    "    study_df = study_df.astype(type_dict)\n",
    "    \n",
    "    return study_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0719164",
   "metadata": {},
   "source": [
    "### Simulating the MRT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8277d689",
   "metadata": {},
   "outputs": [],
   "source": [
    "def simulate_MRT(T, n, env_params, RL_alg):\n",
    "    study_df = make_empty_study_df(T, n)\n",
    "    \n",
    "    # Loop over decision times\n",
    "    for t in range(1,T+1):\n",
    "    \n",
    "        # Loop over users in the study\n",
    "        all_states = []\n",
    "        all_actions = []\n",
    "        all_action1_probs = []\n",
    "        all_rewards = []\n",
    "        for user_id in range(1,n+1):\n",
    "        \n",
    "            # Generate state\n",
    "            if t == 1:\n",
    "                state = generate_state(None, None, None, env_params)\n",
    "            else:\n",
    "                state = generate_state(prev_states[user_id-1], \n",
    "                                    prev_actions[user_id-1], \n",
    "                                    prev_rewards[user_id-1], env_params)\n",
    "        \n",
    "            # Form action selection probabilities\n",
    "            action, action1_prob = RL_alg.select_action(state, user_id)\n",
    "            \n",
    "        \n",
    "            # Generate reward\n",
    "            reward = generate_reward(state, action, env_params)\n",
    "        \n",
    "            # Record data\n",
    "            all_states.append(state)\n",
    "            all_actions.append(action)\n",
    "            all_action1_probs.append(action1_prob)\n",
    "            all_rewards.append(reward)\n",
    "    \n",
    "        # Save all user data\n",
    "        all_states = np.array(all_states)\n",
    "        all_actions = np.array(all_actions)\n",
    "        all_action1_probs = np.array(all_action1_probs)\n",
    "        all_rewards = np.array(all_rewards)\n",
    "        \n",
    "        # Update Algorithm\n",
    "        RL_alg.update_algorithm(new_states = all_states, \n",
    "                     new_actions = all_actions, \n",
    "                     new_rewards = all_rewards, \n",
    "                     new_user_ids = np.arange(1,n+1))\n",
    "    \n",
    "        idx_t = study_df.index[study_df['decision_t'] == t]\n",
    "        half_row_data = np.vstack([all_rewards, all_actions, all_action1_probs]).T\n",
    "        row_data = np.hstack([half_row_data, all_states])      \n",
    "        study_df.iloc[idx_t,2:] = row_data\n",
    "        \n",
    "        # Prepare for next decision time\n",
    "        prev_states = all_states\n",
    "        prev_actions = all_actions\n",
    "        prev_rewards = all_rewards\n",
    "    \n",
    "\n",
    "    type_dict = {\n",
    "        'action': int,\n",
    "        'intercept': int,\n",
    "        'binary': int,\n",
    "    }\n",
    "    study_df = study_df.astype(type_dict)\n",
    "    return study_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ee6fdd37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Treatment Prob: 0.5832820660809711\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>decision_t</th>\n",
       "      <th>reward</th>\n",
       "      <th>action</th>\n",
       "      <th>action1_prob</th>\n",
       "      <th>intercept</th>\n",
       "      <th>binary</th>\n",
       "      <th>continuous</th>\n",
       "      <th>dosage</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.215127</td>\n",
       "      <td>0</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2.197827</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2.936776</td>\n",
       "      <td>1</td>\n",
       "      <td>0.544893</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4.377510</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1.499297</td>\n",
       "      <td>0</td>\n",
       "      <td>0.563411</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2.832585</td>\n",
       "      <td>0.050000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1.872682</td>\n",
       "      <td>1</td>\n",
       "      <td>0.555602</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2.994290</td>\n",
       "      <td>0.047500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>2.152184</td>\n",
       "      <td>1</td>\n",
       "      <td>0.567990</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4.139551</td>\n",
       "      <td>0.095125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>1.432369</td>\n",
       "      <td>1</td>\n",
       "      <td>0.572140</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2.941154</td>\n",
       "      <td>0.140369</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>1.805764</td>\n",
       "      <td>1</td>\n",
       "      <td>0.570170</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2.093228</td>\n",
       "      <td>0.183350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>0.844827</td>\n",
       "      <td>0</td>\n",
       "      <td>0.594030</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4.489415</td>\n",
       "      <td>0.224183</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>2.564130</td>\n",
       "      <td>1</td>\n",
       "      <td>0.576619</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2.209942</td>\n",
       "      <td>0.212974</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>2.971348</td>\n",
       "      <td>1</td>\n",
       "      <td>0.581493</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3.550368</td>\n",
       "      <td>0.252325</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id  decision_t    reward  action  action1_prob  intercept  binary  \\\n",
       "0        1           1  1.215127       0      0.500000          1       0   \n",
       "1        1           2  2.936776       1      0.544893          1       1   \n",
       "2        1           3  1.499297       0      0.563411          1       0   \n",
       "3        1           4  1.872682       1      0.555602          1       0   \n",
       "4        1           5  2.152184       1      0.567990          1       0   \n",
       "5        1           6  1.432369       1      0.572140          1       0   \n",
       "6        1           7  1.805764       1      0.570170          1       0   \n",
       "7        1           8  0.844827       0      0.594030          1       0   \n",
       "8        1           9  2.564130       1      0.576619          1       1   \n",
       "9        1          10  2.971348       1      0.581493          1       0   \n",
       "\n",
       "   continuous    dosage  \n",
       "0    2.197827  0.000000  \n",
       "1    4.377510  0.000000  \n",
       "2    2.832585  0.050000  \n",
       "3    2.994290  0.047500  \n",
       "4    4.139551  0.095125  \n",
       "5    2.941154  0.140369  \n",
       "6    2.093228  0.183350  \n",
       "7    4.489415  0.224183  \n",
       "8    2.209942  0.212974  \n",
       "9    3.550368  0.252325  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "T = 50\n",
    "n = 100\n",
    "pi_min = 0.1\n",
    "b_steep = 1\n",
    "\n",
    "# Form Decision Making Policy and Run MRT Study\n",
    "RL_alg = PoolingBoltzmanSampler(n=n, pi_min=pi_min, b_steep=b_steep)\n",
    "study_df = simulate_MRT(T, n, env_params, RL_alg)\n",
    "\n",
    "# Print first 10 rows of dataframe\n",
    "print(\"Average Treatment Prob: {}\".format(np.mean(study_df['action1_prob'])))\n",
    "print(\"\")\n",
    "study_df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4024acd8",
   "metadata": {},
   "source": [
    "# Part 2: Analyze Pooling RL MRT Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d543b749",
   "metadata": {},
   "source": [
    "## Estimating Causal Excursion Effect \n",
    "$$\n",
    "\\theta^\\star = \\mathbb{E}_{\\pi^\\star} \\left[ Y_{t+1}( \\bar A_{t-1}, 1 ) - Y_{t+1}( \\bar A_{t-1}, 0 ) \\right]\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\hat{\\theta} = \\mathrm{argmin_{(\\theta_0, \\theta_1) \\in \\mathbb{R}^2}} \\left\\{ \\frac{1}{n} \\sum_{i=1}^n \\sum_{t=1}^T \\left( Y_{i,t+1} - \\psi(H_{i,t-1}, O_{i,t})^\\top \\theta_0 - A_{i,t} \\theta_1 \\right)^2 \\right\\}\n",
    "$$\n",
    "where $\\psi(H_{i,t-1}, O_{i,t}) = [1, C_{i,t}]$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cf14fb78",
   "metadata": {},
   "outputs": [],
   "source": [
    "def form_feat_matrix(study_df, base_feat_names, treat_feat_names):\n",
    "    base_feats = np.vstack([study_df[feat] for feat in base_feat_names]).T\n",
    "    treat_feats = np.vstack([study_df[feat] for feat in treat_feat_names]).T\n",
    "    actions = actions = study_df['action']\n",
    "\n",
    "    actions = np.expand_dims(actions, 1)\n",
    "    feat_matrix = np.concatenate([ base_feats, actions*treat_feats], axis=1)\n",
    "        \n",
    "    return feat_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dfcba11d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimated excursion effect (theta_1):\n",
      "[0.45426671]\n"
     ]
    }
   ],
   "source": [
    "# Form Least Squares Estimator\n",
    "Y_vec = study_df['reward'].to_numpy()\n",
    "all_user_ids = study_df['user_id'].to_numpy()\n",
    "feat_matrix = form_feat_matrix(study_df, \n",
    "                               base_feat_names = [\"intercept\", \"continuous\"],\n",
    "                               treat_feat_names = [\"intercept\"])\n",
    "\n",
    "# Fit Linear Model\n",
    "reg = LinearRegression().fit(feat_matrix, Y_vec)\n",
    "thetahat = reg.coef_.copy()\n",
    "thetahat[0] = reg.intercept_\n",
    "\n",
    "print(\"Estimated excursion effect (theta_1):\")\n",
    "print( thetahat[-1:] )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab3b1d91",
   "metadata": {},
   "source": [
    "## Estimating Variance via Standard Sandwich Variance\n",
    "\n",
    "### Standard Sandwich Variance Estimator: $\\big( \\ddot{L}^{(n)} \\big)^{-1} \\Sigma^{(n)} \\big( \\ddot{L}^{(n)} \\big)^{-1, \\top}$\n",
    "\n",
    "- $\\ddot{L}^{(n)}$ is an estimate of the Hessian or \"bread\" part of the sandwich variance:\n",
    "$$\n",
    "\\ddot{L}^{(n)} \\triangleq - \\frac{1}{n} \\sum_{i=1}^n \\sum_{t=1}^T \\begin{bmatrix} \\psi(H_{i,t-1}, O_{i,t}) \\\\ A_{i,t} \\end{bmatrix}^{\\otimes 2}\n",
    "$$\n",
    "(we use the notation $x^{\\otimes 2} \\triangleq x x^\\top$ for any vector $x$)\n",
    "\n",
    "- $\\hat{\\Sigma}^{(n)}$ is an estimate of the \"meat\" part of the sandwich variance:\n",
    "$$\n",
    "\\hat{\\Sigma}^{(n)} \\triangleq \\frac{1}{n} \\sum_{i=1}^n \\dot{\\ell}_i(\\hat\\theta)^{\\otimes 2}\n",
    "$$\n",
    "where $\\dot{\\ell}_i(\\theta) \\triangleq \\sum_{t=1}^T \\left( Y_{i,t+1} - \\psi(H_{i,t-1}, O_{i,t})^\\top \\theta_0 - A_{i,t} \\theta_1 \\right) \\begin{bmatrix} \\psi(H_{i,t-1}, O_{i,t}) \\\\ A_{i,t} \\end{bmatrix}$\n",
    "\n",
    "Above, we use $\\psi(H_{i,t-1}, O_{i,t}) = [1, C_{i,t}]$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3ea455bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def least_squares_est_eqns(feat_matrix, thetahat, Y_vec, all_user_ids):\n",
    "    residuals = Y_vec - np.matmul(feat_matrix, thetahat)\n",
    "    residuals = np.expand_dims(residuals, 1)\n",
    "    raw_est_eqns = residuals * feat_matrix\n",
    "    est_eqns = npi.group_by(all_user_ids).sum(raw_est_eqns)\n",
    "    return est_eqns\n",
    "\n",
    "\n",
    "def least_squares_hessian(feat_matrix):\n",
    "    hessian = -np.einsum('ij,ik->ijk', feat_matrix, feat_matrix).mean(0)\n",
    "    return hessian"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9b2ce302",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sandwich_variance(est_eqns, hessian, thetahat):\n",
    "    meat = np.einsum( 'ij,ik->jk', est_eqns, est_eqns )\n",
    "    meat = meat / n\n",
    "\n",
    "    inv_hessian = np.linalg.inv( hessian )\n",
    "    sandwich_var = np.matmul( np.matmul(inv_hessian, meat), inv_hessian )\n",
    "    sandwich_var = sandwich_var / n\n",
    "    return sandwich_var"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "80cce04c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimated sandwich variance for theta_1:\n",
      "0.775056610915535\n"
     ]
    }
   ],
   "source": [
    "_, theta_est_eqns = least_squares_est_eqns(feat_matrix, thetahat, Y_vec, all_user_ids)\n",
    "theta_hessian = least_squares_hessian(feat_matrix)\n",
    "sandwich_var = get_sandwich_variance(theta_est_eqns, theta_hessian, thetahat)\n",
    "\n",
    "print(\"Estimated sandwich variance for theta_1:\")\n",
    "print( sandwich_var[-1][-1] )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1d8ee21",
   "metadata": {},
   "source": [
    "## Estimating Variance via Adaptive Sandwich Variance\n",
    "\n",
    "### Adaptive Sandwich Variance Estimator: $\\big( \\ddot{L}^{(n)} \\big)^{-1} \\Sigma_{\\mathrm{adapt}}^{(n)} \\big( \\ddot{L}^{(n)} \\big)^{-1, \\top}$\n",
    "\n",
    "Note that $\\big( \\ddot{L}^{(n)} \\big)^{-1} \\Sigma_{\\mathrm{adapt}}^{(n)} \\big( \\ddot{L}^{(n)} \\big)^{-1, \\top}$ is equivalent to the bottom right block of the matrix \n",
    "$$\\begin{bmatrix} \\ddot{G}_{1:T-1}^{(n)} & 0 \\\\\n",
    "V_{1:T-1}^{(n)} & \\ddot{L}^{(n)} \\end{bmatrix}^{-1} \\Sigma_{1:T}^{(n)} \\begin{bmatrix} \\ddot{G}_{1:T-1}^{(n)} & 0 \\\\\n",
    "V_{1:T-1}^{(n)} & \\ddot{L}^{(n)} \\end{bmatrix}^{-1, \\top}$$\n",
    "where\n",
    "$\\Sigma_{1:T}^{(n)}$ is an estimate of the \"stacked meat\" part of the adaptive sandwich variance:\n",
    "$$\n",
    "\\Sigma_{1:T}^{(n)} \\triangleq \\frac{1}{n} \\sum_{i=1}^n \\begin{pmatrix} \\dot{g}_{i,1}(\\hat\\beta_1) \\\\\n",
    "\\dot{g}_{i,2}(\\hat\\beta_2) \\\\\n",
    "\\vdots \\\\\n",
    "\\dot{g}_{i,T-1}(\\hat\\beta_{T-1}) \\\\\n",
    "\\dot{\\ell}_i(\\hat{\\theta}) \\end{pmatrix}^{\\otimes 2}\n",
    "$$\n",
    "where $\\dot{\\ell}_i(\\theta) \\triangleq \\sum_{t=1}^T \\left( Y_{i,t+1} - \\psi(H_{i,t-1}, O_{i,t})^\\top \\theta_0 - A_{i,t} \\theta_1 \\right) \\begin{bmatrix} \\psi(H_{i,t-1}, O_{i,t}) \\\\ A_{i,t} \\end{bmatrix}$ and\n",
    "$\\dot{g}_{i,t}(\\beta_t) \\triangleq \\sum_{t'=1}^t \\left( R_{i,t'+1} - \\phi_0(S_{t'})^\\top \\beta_0 - A_{i,t'} \\phi_1(S_{i,t'})^\\top \\beta_1 \\right) \\begin{bmatrix} \\phi_0(S_{t'}) \\\\ A_{i,t'} \\phi_1(S_{i,t'}) \\end{bmatrix}$\n",
    "\n",
    "(we use the notation $x^{\\otimes 2} \\triangleq x x^\\top$ for any vector $x$)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "63678f56",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_stacked_est_eqns(RL_alg, theta_est_eqns):\n",
    "\n",
    "    all_est_eqns = []\n",
    "    for policy_dict in RL_alg.all_policies:\n",
    "        policy_num = policy_dict['policy_num']\n",
    "        if policy_num in [0, T]:\n",
    "            continue\n",
    "        tmp_est_eqns = RL_alg.all_policies[1]['est_eqns']\n",
    "        all_est_eqns.append(tmp_est_eqns)\n",
    "\n",
    "    all_est_eqns.append(theta_est_eqns)\n",
    "    stacked_est_eqns = np.concatenate(all_est_eqns, axis=1)\n",
    "    \n",
    "    return stacked_est_eqns\n",
    "\n",
    "\n",
    "def get_weight_derivates(RL_alg):\n",
    "    all_W_grads = {}\n",
    "    \n",
    "    for policy_num in RL_alg.all_decisions.keys():\n",
    "        if policy_num == 0:\n",
    "            continue\n",
    "\n",
    "        tmp_pi_grad = np.array(RL_alg.all_decisions[policy_num]['all_pi_grad'])\n",
    "        tmp_actions = np.array(RL_alg.all_decisions[policy_num]['all_actions'])\n",
    "        tmp_action1_probs = np.array(RL_alg.all_decisions[policy_num]['all_action1_probs'])\n",
    "\n",
    "        tmp_actions = np.expand_dims(tmp_actions, 1)\n",
    "        tmp_action1_probs = np.expand_dims(tmp_action1_probs, 1)\n",
    "\n",
    "        W_grads = tmp_pi_grad * tmp_actions / tmp_action1_probs \\\n",
    "                    - tmp_pi_grad * (1-tmp_actions) / (1-tmp_action1_probs)\n",
    "    \n",
    "        all_W_grads[policy_num] = W_grads\n",
    "    \n",
    "    return all_W_grads\n",
    "\n",
    "def get_stacked_hessian(RL_alg, theta_est_eqns, theta_hessian):\n",
    "    # Collect Hessians (Block Diagonal)\n",
    "    alg_hessian = []\n",
    "    for policy_dict in RL_alg.all_policies:\n",
    "        policy_num = policy_dict['policy_num']\n",
    "        if policy_num in [0, T]:\n",
    "            continue\n",
    "        hessian = RL_alg.all_policies[policy_num]['hessian']\n",
    "        alg_hessian.append(hessian)\n",
    "\n",
    "    # Get Estimating Equations\n",
    "    stacked_est_eqns = get_stacked_est_eqns(RL_alg, theta_est_eqns)\n",
    "\n",
    "    # Outer produt of W grads and estimating equations\n",
    "    all_W_grads = get_weight_derivates(RL_alg)\n",
    "    all_columns = []\n",
    "    for policy_num in all_W_grads.keys():\n",
    "        col = np.einsum('ij,ik->jk', stacked_est_eqns, all_W_grads[policy_num]) / n\n",
    "        all_columns.append( col )\n",
    "\n",
    "    # Form Stacked hessian\n",
    "    beta_dim = alg_hessian[0].shape[0]\n",
    "    theta_dim = theta_hessian.shape[0]\n",
    "\n",
    "    stacked_hessian_col = []\n",
    "    for policy_dict in RL_alg.all_policies:\n",
    "        policy_num = policy_dict['policy_num']\n",
    "        if policy_num in [0, T]:\n",
    "            continue\n",
    "        zeros = np.zeros(((policy_num-1)*beta_dim, beta_dim))\n",
    "        tmp_hessian = alg_hessian[policy_num-1]\n",
    "        tmp_col = np.concatenate([ zeros, tmp_hessian, all_columns[policy_num-1][policy_num*beta_dim:] ], axis=0 )\n",
    "        stacked_hessian_col.append( tmp_col )\n",
    "    \n",
    "    zeros = np.zeros(((T-1)*beta_dim, theta_dim))\n",
    "    last_col = np.concatenate([zeros, theta_hessian])\n",
    "    stacked_hessian_col.append(last_col)\n",
    "    stacked_hessian = np.hstack(stacked_hessian_col)\n",
    "    \n",
    "    return stacked_hessian\n",
    "\n",
    "def get_adaptive_sandwich_variance(stacked_est_eqns, stacked_hessian):\n",
    "    inv_stacked_hessian = np.linalg.inv( stacked_hessian )\n",
    "    stacked_meat = np.einsum('ij,ik->jk', stacked_est_eqns, stacked_est_eqns) / n\n",
    "    stacked_sandwich = np.matmul( np.matmul(inv_stacked_hessian, stacked_meat), inv_stacked_hessian.T ) / n\n",
    "    return stacked_sandwich"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "69794feb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimated adaptive sandwich variance for theta_1:\n",
      "0.7928601489728864\n"
     ]
    }
   ],
   "source": [
    "# Get Estimating Equations\n",
    "stacked_est_eqns = get_stacked_est_eqns(RL_alg, theta_est_eqns)\n",
    "stacked_hessian = get_stacked_hessian(RL_alg, theta_est_eqns, theta_hessian)\n",
    "\n",
    "stacked_sandwich = get_adaptive_sandwich_variance(stacked_est_eqns, stacked_hessian)\n",
    "\n",
    "print(\"Estimated adaptive sandwich variance for theta_1:\")\n",
    "print( stacked_sandwich[-1,-1] )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "464d0cf7",
   "metadata": {},
   "source": [
    "## Exercises\n",
    "\n",
    "(1) Compare Standard Sandwich and Adaptive Sandwich Variance Estimators\n",
    "\n",
    "(2) Examine the `b_steep` argument Boltzmann sampling hyperparameter\n",
    "    $$\\mathbb{P}(A_{i,t} = 1 | H_{1:n,t}, S_{i,t}) = \\pi_\\min + (1-2\\pi_\\min) * \\left[ 1 + \\exp \\left( - b_{\\mathrm{steep}} \\phi_1(S_{i,t})^\\top \\hat{\\beta}_{t-1,1} \\right) \\right]^{-1}$$\n",
    "    \n",
    "   (2a) How does changing $b_{\\mathrm{steep}} > 0$ change the action selection probabilities? Can make a plot.\n",
    "    \n",
    "   (2b) How does changing `b_steep` affect the sandwich and adaptive sandwich variance estimators? For example, compare `b_steep = 5` vs `b_steep = 1`\n",
    "    \n",
    "(3) Examine the Posterior Sampling and epsilon-greedy algorithms you looked at earlier in Raaz's coding session. Show that these algorithms do not converge to a limiting policy when the treatment effect (or margin) is zero. Compare this to using a Botlzmann sampling algorithm\n",
    "\n",
    "\n",
    "__Optional / Additional Exercises:__\n",
    "- Use the sandwich and adaptive sandwich variances to form 95% confidence intervals for $\\theta_1^\\star$\n",
    "- How does changing the data generating environment affect the sandwich and adaptive sandwich variance estimators?\n",
    "- How does changing the model used to form $\\theta$ affect the sandwich and adaptive sandwich variance estimators? Can look at excursion effects conditioned on state.\n",
    "- Compare to the individual RL algorithm to personalize, as used in the Monday afternoon exercise"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "074bf060",
   "metadata": {},
   "source": [
    "# Solutions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "32802efc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def logistic_function(x, pi_min, b_steep):\n",
    "    return pi_min + (1-2*pi_min) / ((1 + np.exp(-b_steep * x)))\n",
    "\n",
    "# Generate x values\n",
    "x = np.linspace(-3, 3, 500)\n",
    "\n",
    "# Compute y values using the generalized logistic function\n",
    "y1 = logistic_function(x, pi_min, b_steep=1)\n",
    "y5 = logistic_function(x, pi_min, b_steep=5)\n",
    "\n",
    "# Plot the generalized logistic function\n",
    "plt.plot(x, y1, label='b_steep = 1', color='blue')\n",
    "plt.plot(x, y5, label='b_steep = 5', color='green')\n",
    "plt.xlabel('x')\n",
    "plt.ylabel('f(x)')\n",
    "plt.ylim(0,1)\n",
    "plt.title('Generalized Logistic Function')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6abacf16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Treatment Prob: 0.8224387619673583\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>decision_t</th>\n",
       "      <th>reward</th>\n",
       "      <th>action</th>\n",
       "      <th>action1_prob</th>\n",
       "      <th>intercept</th>\n",
       "      <th>binary</th>\n",
       "      <th>continuous</th>\n",
       "      <th>dosage</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2.041791</td>\n",
       "      <td>1</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3.191668</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1.524209</td>\n",
       "      <td>0</td>\n",
       "      <td>0.804439</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3.232629</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1.510612</td>\n",
       "      <td>1</td>\n",
       "      <td>0.757659</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2.659192</td>\n",
       "      <td>0.950000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0.145476</td>\n",
       "      <td>1</td>\n",
       "      <td>0.838512</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3.087327</td>\n",
       "      <td>0.952500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1.583447</td>\n",
       "      <td>1</td>\n",
       "      <td>0.837272</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.342691</td>\n",
       "      <td>0.954875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>1.616093</td>\n",
       "      <td>1</td>\n",
       "      <td>0.829726</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.507763</td>\n",
       "      <td>0.957131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>2.190345</td>\n",
       "      <td>1</td>\n",
       "      <td>0.853908</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3.597751</td>\n",
       "      <td>0.959275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>1.028869</td>\n",
       "      <td>1</td>\n",
       "      <td>0.846364</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3.034398</td>\n",
       "      <td>0.961311</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>1.276377</td>\n",
       "      <td>1</td>\n",
       "      <td>0.840096</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2.871314</td>\n",
       "      <td>0.963245</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>1.399894</td>\n",
       "      <td>1</td>\n",
       "      <td>0.831721</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2.474531</td>\n",
       "      <td>0.965083</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id  decision_t    reward  action  action1_prob  intercept  binary  \\\n",
       "0        1           1  2.041791       1      0.500000          1       0   \n",
       "1        1           2  1.524209       0      0.804439          1       0   \n",
       "2        1           3  1.510612       1      0.757659          1       1   \n",
       "3        1           4  0.145476       1      0.838512          1       0   \n",
       "4        1           5  1.583447       1      0.837272          1       1   \n",
       "5        1           6  1.616093       1      0.829726          1       0   \n",
       "6        1           7  2.190345       1      0.853908          1       1   \n",
       "7        1           8  1.028869       1      0.846364          1       0   \n",
       "8        1           9  1.276377       1      0.840096          1       0   \n",
       "9        1          10  1.399894       1      0.831721          1       0   \n",
       "\n",
       "   continuous    dosage  \n",
       "0    3.191668  1.000000  \n",
       "1    3.232629  1.000000  \n",
       "2    2.659192  0.950000  \n",
       "3    3.087327  0.952500  \n",
       "4    1.342691  0.954875  \n",
       "5    1.507763  0.957131  \n",
       "6    3.597751  0.959275  \n",
       "7    3.034398  0.961311  \n",
       "8    2.871314  0.963245  \n",
       "9    2.474531  0.965083  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "T = 50\n",
    "n = 100\n",
    "pi_min = 0.1\n",
    "b_steep = 5\n",
    "\n",
    "# Form Decision Making Policy and Run MRT Study\n",
    "RL_alg = PoolingBoltzmanSampler(n=n, pi_min=pi_min, b_steep=b_steep)\n",
    "study_df = simulate_MRT(T, n, env_params, RL_alg)\n",
    "\n",
    "# Print first 10 rows of dataframe\n",
    "print(\"Average Treatment Prob: {}\".format(np.mean(study_df['action1_prob'])))\n",
    "print(\"\")\n",
    "study_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "06ebfe65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimated sandwich variance for theta_1:\n",
      "0.775056610915535\n"
     ]
    }
   ],
   "source": [
    "_, theta_est_eqns = least_squares_est_eqns(feat_matrix, thetahat, Y_vec, all_user_ids)\n",
    "theta_hessian = least_squares_hessian(feat_matrix)\n",
    "sandwich_var = get_sandwich_variance(theta_est_eqns, theta_hessian, thetahat)\n",
    "\n",
    "print(\"Estimated sandwich variance for theta_1:\")\n",
    "print( sandwich_var[-1][-1] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "06a1c475",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimated adaptive sandwich variance for theta_1:\n",
      "0.8771407842455797\n"
     ]
    }
   ],
   "source": [
    "# Get Estimating Equations\n",
    "stacked_est_eqns = get_stacked_est_eqns(RL_alg, theta_est_eqns)\n",
    "stacked_hessian = get_stacked_hessian(RL_alg, theta_est_eqns, theta_hessian)\n",
    "\n",
    "stacked_sandwich = get_adaptive_sandwich_variance(stacked_est_eqns, stacked_hessian)\n",
    "\n",
    "print(\"Estimated adaptive sandwich variance for theta_1:\")\n",
    "print( stacked_sandwich[-1,-1] )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12984a1a",
   "metadata": {},
   "source": [
    "## For additional solutions, see the slides \"Kelly - Tuesday Afternoon - Inference after Pooling Practical\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7856d98d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
